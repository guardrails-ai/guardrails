import CodeOutputBlock from '../../docusaurus/code-output-block.jsx';

```bash
guardrails hub install hub://brainlogic/high_quality_translation
```

<CodeOutputBlock lang="bash">

```
    Installing hub://brainlogic/high_quality_translation...
    [ ===] Fetching manifestst
    [=   ] Downloading dependenciespendencies  Running command git clone --filter=blob:none --quiet https://github.com/BrainLogicHub/high_quality_translation_validator.git /private/var/folders/yt/ltz0vbpx14j34mj55jyj39x40000gn/T/pip-req-build-hja54mr_
    [   =] Downloading dependenciesWARNING: typer 0.12.5 does not provide the extra 'all'
    [=== ] Downloading dependencies
    Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 45590.26it/s]
    [ ===] Running post-install setupLightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/b3a8aea5a5fc22db68a554b92b3d96eb6ea75cc9/checkpoints/model.ckpt`
    [=   ] Running post-install setup/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
      warnings.warn(
    [=== ] Running post-install setupEncoder model frozen.
    [ ===] Running post-install setup/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
    [=== ] Running post-install setup
    âœ…Successfully installed brainlogic/high_quality_translation!
    
    
    Import validator:
    from guardrails.hub import HighQualityTranslation
    
    Get more info:
    https://hub.guardrailsai.com/validator/brainlogic/high_quality_translation
    
```

</CodeOutputBlock>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file. -->

# Translate text with quality checks

**Note:**
To download this example as a Jupyter notebook, click [here](https://github.com/guardrails-ai/guardrails/blob/main/docs/examples/translation_with_quality_check.ipynb).

In this example, we will use Guardrails during the translation of a statement from another language to English. We will check whether the translated statement is likely of high quality.

## Objective

We want to translate a statement from different languages to English and ensure that the translated statement accurately reflects the original content.

### Setup

- Install the `unbabel-comet` from source:
  `pip install git+https://github.com/Unbabel/COMET`
- Please accept the model license from:
  https://huggingface.co/Unbabel/wmt22-cometkiwi-da
- Login into Huggingface Hub using:
  huggingface-cli login --token $HUGGINGFACE_TOKEN



```python
from guardrails import Guard
from rich import print
from guardrails.hub import HighQualityTranslation
```

## Step 1: Define a Guard that uses the validator

This guard will use the HighQualityTranslation validator to validate some string outputs.


We define the prompt and the guard.


```python
prompt = """
Translate the given statement into English:

${statement_to_be_translated}
"""

guard = Guard().use(HighQualityTranslation(on_fail="fix"))
```

<CodeOutputBlock lang="python">

```
    Loading the model Unbabel/wmt22-cometkiwi-da...



    Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]


    Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/b3a8aea5a5fc22db68a554b92b3d96eb6ea75cc9/checkpoints/model.ckpt`
    /Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
      warnings.warn(
    Encoder model frozen.
    /Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
```

</CodeOutputBlock>

## Step 2: Wrap the LLM API call with `Guard`


First, let's try translating a statement that is relatively easy to translate.



```python
# Set your OPENAI_API_KEY as an environment variable
# import os
# os.environ["OPENAI_API_KEY"] = "YOUR_API_KEY"

statement = "Ich habe keine Ahnung, was ich hier schreiben soll."

res = guard(
    messages=[{"role": "user", "content": prompt}],
    prompt_params={"statement_to_be_translated": statement},
    metadata={"translation_source": statement},
    model="gpt-3.5-turbo",
    max_tokens=1024,
    temperature=0,
)

print(f"Raw LLM Output: {res.raw_llm_output}")
print(f"Validated Output: {res.validated_output}")
```
    
<CodeOutputBlock dangerouslySetInnerHTML={{ __html: "HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"<br />    [92m10:09:59 - LiteLLM:INFO[0m: utils.py:2963 - <br />    LiteLLM completion() model= gpt-3.5-turbo; provider = openai<br />    <br />    LiteLLM completion() model= gpt-3.5-turbo; provider = openai<br />    HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"<br />    [92m10:09:59 - LiteLLM:INFO[0m: utils.py:989 - Wrapper: Completed Call, calling success_handler<br />    Wrapper: Completed Call, calling success_handler<br />    /Users/dtam/dev/guardrails/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.<br />      warnings.warn(<br />    /Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:<br />      Expected `PromptTokensDetails` but got `dict` with value `{'audio_tokens': None, 'cached_tokens': 0}` - serialized value may not be as expected<br />      return self.__pydantic_serializer__.to_python(<br />    GPU available: True (mps), used: False<br />    TPU available: False, using: 0 TPU cores<br />    HPU available: False, using: 0 HPUs<br />    /Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.<br />    /Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.<br />    Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.15it/s]<br /><br /><br /><br /><br /><pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM Output: I have no idea what I should write here.<br /></pre><br />```<br /><br /><br /><br /><br /><pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validated Output: I have no idea what I should write here.<br /></pre>"}} />

We can look at the logs to see the quality check results:



```python
print(guard.history.last.tree)
```
    
<CodeOutputBlock dangerouslySetInnerHTML={{ __html: "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logs<br />â””â”€â”€ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Step 0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®<br />    â”‚ <span style=\"background-color: #e7dfeb\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span> Messages <span style=\"background-color: #e7dfeb\">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”ƒ</span><span style=\"background-color: #e7dfeb; font-weight: bold\"> Role </span><span style=\"background-color: #e7dfeb\">â”ƒ</span><span style=\"background-color: #e7dfeb; font-weight: bold\"> Content                                             </span><span style=\"background-color: #e7dfeb\">â”ƒ                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”¡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”‚ user â”‚                                                     â”‚                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”‚      â”‚ Translate the given statement into English:         â”‚                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”‚      â”‚                                                     â”‚                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”‚      â”‚ Ich habe keine Ahnung, was ich hier schreiben soll. â”‚                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â”‚      â”‚                                                     â”‚                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span> â”‚<br />    â”‚ <span style=\"background-color: #f5f5dc\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span> Raw LLM Output <span style=\"background-color: #f5f5dc\">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span> â”‚<br />    â”‚ <span style=\"background-color: #f5f5dc\">â”‚ I have no idea what I should write here.                                                                â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #f5f5dc\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span> â”‚<br />    â”‚ <span style=\"background-color: #f0fff0\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span> Validated Output <span style=\"background-color: #f0fff0\">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span> â”‚<br />    â”‚ <span style=\"background-color: #f0fff0\">â”‚ I have no idea what I should write here.                                                                â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #f0fff0\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span> â”‚<br />    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯<br /></pre>"}} />

The `guard` wrapper returns the raw LLM response, which is the translated statement and also the validated output. In this case, the translated statement was of a good quality (above the threshold of 0.5), so the validated output is the same as the raw LLM response.

#### Now, let's test with a really low quality translation, and see how Guardrails handles it.



```python
# Parse the code snippet
statement = "à¤…à¤°à¥‡ à¤­à¤¾à¤Š, à¤†à¤œ à¤°à¤¾à¤¤à¥à¤°à¥€ à¤œà¥‹à¤°à¤¦à¤¾à¤° à¤ªà¤¾à¤°à¥à¤Ÿà¥€ à¤®à¤¾à¤°à¥‚à¤¯à¤¾, à¤œà¤®à¥‚à¤¨ à¤Ÿà¤¾à¤•à¥‚à¤¯à¤¾ à¤†à¤£à¤¿ à¤§à¤®à¤¾à¤² à¤•à¤°à¥‚à¤¯à¤¾!"

## Ideal translation from Marathi -> English:
#  "Hey bro, let's have a great party tonight and have fun!"

output = guard.parse(
    llm_output="It's such a beautiful day, I'm going to the beach.",  ## here, providing a really bad translation
    metadata={"translation_source": statement},
)

# Print the output
print(f"Raw LLM Output: {output.raw_llm_output}")
print(f"Validated Output: {output.validated_output}")
```
    
<CodeOutputBlock dangerouslySetInnerHTML={{ __html: "/Users/dtam/dev/guardrails/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.<br />      warnings.warn(<br />    GPU available: True (mps), used: False<br />    TPU available: False, using: 0 TPU cores<br />    HPU available: False, using: 0 HPUs<br />    /Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.<br />    /Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.<br />    Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.53it/s]<br /><br /><br /><br /><br /><pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM Output: It's such a beautiful day, I'm going to the beach.<br /></pre><br />```<br /><br /><br /><br /><br /><pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validated Output: <br /></pre>"}} />


```python
print(guard.history.last.tree)
```
    
<CodeOutputBlock dangerouslySetInnerHTML={{ __html: "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logs<br />â””â”€â”€ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Step 0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®<br />    â”‚ <span style=\"background-color: #e7dfeb\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span> Messages <span style=\"background-color: #e7dfeb\">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â”‚ No messages.                                                                                            â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #e7dfeb\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span> â”‚<br />    â”‚ <span style=\"background-color: #f5f5dc\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span> Raw LLM Output <span style=\"background-color: #f5f5dc\">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span> â”‚<br />    â”‚ <span style=\"background-color: #f5f5dc\">â”‚ It's such a beautiful day, I'm going to the beach.                                                      â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #f5f5dc\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span> â”‚<br />    â”‚ <span style=\"background-color: #f0fff0\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span> Validated Output <span style=\"background-color: #f0fff0\">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span> â”‚<br />    â”‚ <span style=\"background-color: #f0fff0\">â”‚ ''                                                                                                      â”‚</span> â”‚<br />    â”‚ <span style=\"background-color: #f0fff0\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span> â”‚<br />    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯<br /></pre>"}} />

As you can see, the translation quality is really bad, and the `HighQualityTranslation` check failed as the translation quality was below the threshold. The validated response is an empty string.

## In this way, you can use Guardrails to ensure that the output of your LLM is of high quality.

