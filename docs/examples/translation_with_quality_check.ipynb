{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/brainlogic/\u001b[0m\u001b[95mhigh_quality_translation...\u001b[0m\n",
      "\u001b[2K\u001b[32m[ ===]\u001b[0m Fetching manifestst\n",
      "\u001b[2K\u001b[32m[=   ]\u001b[0m Downloading dependenciespendencies  Running command git clone --filter=blob:none --quiet https://github.com/BrainLogicHub/high_quality_translation_validator.git /private/var/folders/yt/ltz0vbpx14j34mj55jyj39x40000gn/T/pip-req-build-hja54mr_\n",
      "\u001b[2K\u001b[32m[   =]\u001b[0m Downloading dependencies\u001b[33mWARNING: typer 0.12.5 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[2K\u001b[32m[=== ]\u001b[0m Downloading dependencies\n",
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 45590.26it/s]\n",
      "\u001b[2K\u001b[32m[ ===]\u001b[0m Running post-install setupLightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/b3a8aea5a5fc22db68a554b92b3d96eb6ea75cc9/checkpoints/model.ckpt`\n",
      "\u001b[2K\u001b[32m[=   ]\u001b[0m Running post-install setup/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "\u001b[2K\u001b[32m[=== ]\u001b[0m Running post-install setupEncoder model frozen.\n",
      "\u001b[2K\u001b[32m[ ===]\u001b[0m Running post-install setup/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "\u001b[2K\u001b[32m[=== ]\u001b[0m Running post-install setup\n",
      "\u001b[1A\u001b[2K✅Successfully installed brainlogic/high_quality_translation!\n",
      "\n",
      "\n",
      "\u001b[1mImport validator:\u001b[0m\n",
      "from guardrails.hub import HighQualityTranslation\n",
      "\n",
      "\u001b[1mGet more info:\u001b[0m\n",
      "\u001b[4;94mhttps://hub.guardrailsai.com/validator/brainlogic/high_quality_translation\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!guardrails hub install hub://brainlogic/high_quality_translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate text with quality checks\n",
    "\n",
    "**Note:**\n",
    "To download this example as a Jupyter notebook, click [here](https://github.com/guardrails-ai/guardrails/blob/main/docs/examples/translation_with_quality_check.ipynb).\n",
    "\n",
    "In this example, we will use Guardrails during the translation of a statement from another language to English. We will check whether the translated statement is likely of high quality.\n",
    "\n",
    "## Objective\n",
    "\n",
    "We want to translate a statement from different languages to English and ensure that the translated statement accurately reflects the original content.\n",
    "\n",
    "### Setup\n",
    "\n",
    "- Install the `unbabel-comet` from source:\n",
    "  `pip install git+https://github.com/Unbabel/COMET`\n",
    "- Please accept the model license from:\n",
    "  https://huggingface.co/Unbabel/wmt22-cometkiwi-da\n",
    "- Login into Huggingface Hub using:\n",
    "  huggingface-cli login --token $HUGGINGFACE_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from guardrails import Guard\n",
    "from rich import print\n",
    "from guardrails.hub import HighQualityTranslation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define a Guard that uses the validator\n",
    "\n",
    "This guard will use the HighQualityTranslation validator to validate some string outputs.\n",
    "\n",
    "\n",
    "We define the prompt and the guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model Unbabel/wmt22-cometkiwi-da...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa13706e228473b972844df05c1cdf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/b3a8aea5a5fc22db68a554b92b3d96eb6ea75cc9/checkpoints/model.ckpt`\n",
      "/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Encoder model frozen.\n",
      "/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the given statement into English:\n",
    "\n",
    "${statement_to_be_translated}\n",
    "\"\"\"\n",
    "\n",
    "guard = Guard().use(HighQualityTranslation(on_fail=\"fix\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Wrap the LLM API call with `Guard`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try translating a statement that is relatively easy to translate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:09:59 - LiteLLM:INFO\u001b[0m: utils.py:2963 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:09:59 - LiteLLM:INFO\u001b[0m: utils.py:989 - Wrapper: Completed Call, calling success_handler\n",
      "Wrapper: Completed Call, calling success_handler\n",
      "/Users/dtam/dev/guardrails/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n",
      "/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `PromptTokensDetails` but got `dict` with value `{'audio_tokens': None, 'cached_tokens': 0}` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM Output: I have no idea what I should write here.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM Output: I have no idea what I should write here.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validated Output: I have no idea what I should write here.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validated Output: I have no idea what I should write here.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set your OPENAI_API_KEY as an environment variable\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "\n",
    "statement = \"Ich habe keine Ahnung, was ich hier schreiben soll.\"\n",
    "\n",
    "res = guard(\n",
    "    messages=[{\"role\":\"user\", \"content\": prompt}],\n",
    "    prompt_params={\"statement_to_be_translated\": statement},\n",
    "    metadata={\"translation_source\": statement},\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(f\"Raw LLM Output: {res.raw_llm_output}\")\n",
    "print(f\"Validated Output: {res.validated_output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the logs to see the quality check results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logs\n",
       "└── ╭────────────────────────────────────────────────── Step 0 ───────────────────────────────────────────────────╮\n",
       "    │ <span style=\"background-color: #e7dfeb\">╭───────────────────────────────────────────────</span> Messages <span style=\"background-color: #e7dfeb\">────────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ ┏━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ ┃</span><span style=\"background-color: #e7dfeb; font-weight: bold\"> Role </span><span style=\"background-color: #e7dfeb\">┃</span><span style=\"background-color: #e7dfeb; font-weight: bold\"> Content                                             </span><span style=\"background-color: #e7dfeb\">┃                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ ┡━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ │ user │                                                     │                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ │      │ Translate the given statement into English:         │                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ │      │                                                     │                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ │      │ Ich habe keine Ahnung, was ich hier schreiben soll. │                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ │      │                                                     │                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ └──────┴─────────────────────────────────────────────────────┘                                          │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">╭────────────────────────────────────────────</span> Raw LLM Output <span style=\"background-color: #f5f5dc\">─────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">│ I have no idea what I should write here.                                                                │</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">╭───────────────────────────────────────────</span> Validated Output <span style=\"background-color: #f0fff0\">────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">│ I have no idea what I should write here.                                                                │</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Logs\n",
       "└── ╭────────────────────────────────────────────────── Step 0 ───────────────────────────────────────────────────╮\n",
       "    │ \u001b[48;2;231;223;235m╭─\u001b[0m\u001b[48;2;231;223;235m──────────────────────────────────────────────\u001b[0m Messages \u001b[48;2;231;223;235m───────────────────────────────────────────────\u001b[0m\u001b[48;2;231;223;235m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┏━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┃\u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[1;48;2;231;223;235mRole\u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┃\u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[1;48;2;231;223;235mContent                                            \u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┃\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┡━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235muser\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m                                                   \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m      \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235mTranslate the given statement into English:        \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m      \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m                                                   \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m      \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235mIch habe keine Ahnung, was ich hier schreiben soll.\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m      \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m                                                   \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m└──────┴─────────────────────────────────────────────────────┘\u001b[0m\u001b[48;2;231;223;235m                                         \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m╭─\u001b[0m\u001b[48;2;245;245;220m───────────────────────────────────────────\u001b[0m Raw LLM Output \u001b[48;2;245;245;220m────────────────────────────────────────────\u001b[0m\u001b[48;2;245;245;220m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m│\u001b[0m\u001b[48;2;245;245;220m \u001b[0m\u001b[48;2;245;245;220mI have no idea what I should write here.\u001b[0m\u001b[48;2;245;245;220m                                                               \u001b[0m\u001b[48;2;245;245;220m \u001b[0m\u001b[48;2;245;245;220m│\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m╭─\u001b[0m\u001b[48;2;240;255;240m──────────────────────────────────────────\u001b[0m Validated Output \u001b[48;2;240;255;240m───────────────────────────────────────────\u001b[0m\u001b[48;2;240;255;240m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m│\u001b[0m\u001b[48;2;240;255;240m \u001b[0m\u001b[48;2;240;255;240mI have no idea what I should write here.\u001b[0m\u001b[48;2;240;255;240m                                                               \u001b[0m\u001b[48;2;240;255;240m \u001b[0m\u001b[48;2;240;255;240m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(guard.history.last.tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `guard` wrapper returns the raw LLM response, which is the translated statement and also the validated output. In this case, the translated statement was of a good quality (above the threshold of 0.5), so the validated output is the same as the raw LLM response.\n",
    "\n",
    "#### Now, let's test with a really low quality translation, and see how Guardrails handles it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dtam/dev/guardrails/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/dtam/.pyenv/versions/3.11.3/envs/311lite/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM Output: It's such a beautiful day, I'm going to the beach.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM Output: It's such a beautiful day, I'm going to the beach.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validated Output: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validated Output: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the code snippet\n",
    "statement = \"अरे भाऊ, आज रात्री जोरदार पार्टी मारूया, जमून टाकूया आणि धमाल करूया!\"\n",
    "\n",
    "## Ideal translation from Marathi -> English:\n",
    "#  \"Hey bro, let's have a great party tonight and have fun!\"\n",
    "\n",
    "output = guard.parse(\n",
    "    llm_output=\"It's such a beautiful day, I'm going to the beach.\",  ## here, providing a really bad translation\n",
    "    metadata={\"translation_source\": statement},\n",
    ")\n",
    "\n",
    "# Print the output\n",
    "print(f\"Raw LLM Output: {output.raw_llm_output}\")\n",
    "print(f\"Validated Output: {output.validated_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logs\n",
       "└── ╭────────────────────────────────────────────────── Step 0 ───────────────────────────────────────────────────╮\n",
       "    │ <span style=\"background-color: #e7dfeb\">╭───────────────────────────────────────────────</span> Messages <span style=\"background-color: #e7dfeb\">────────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ No messages.                                                                                            │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">╭────────────────────────────────────────────</span> Raw LLM Output <span style=\"background-color: #f5f5dc\">─────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">│ It's such a beautiful day, I'm going to the beach.                                                      │</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">╭───────────────────────────────────────────</span> Validated Output <span style=\"background-color: #f0fff0\">────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">│ ''                                                                                                      │</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Logs\n",
       "└── ╭────────────────────────────────────────────────── Step 0 ───────────────────────────────────────────────────╮\n",
       "    │ \u001b[48;2;231;223;235m╭─\u001b[0m\u001b[48;2;231;223;235m──────────────────────────────────────────────\u001b[0m Messages \u001b[48;2;231;223;235m───────────────────────────────────────────────\u001b[0m\u001b[48;2;231;223;235m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235mNo messages.\u001b[0m\u001b[48;2;231;223;235m                                                                                           \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m╭─\u001b[0m\u001b[48;2;245;245;220m───────────────────────────────────────────\u001b[0m Raw LLM Output \u001b[48;2;245;245;220m────────────────────────────────────────────\u001b[0m\u001b[48;2;245;245;220m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m│\u001b[0m\u001b[48;2;245;245;220m \u001b[0m\u001b[48;2;245;245;220mIt's such a beautiful day, I'm going to the beach.\u001b[0m\u001b[48;2;245;245;220m                                                     \u001b[0m\u001b[48;2;245;245;220m \u001b[0m\u001b[48;2;245;245;220m│\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m╭─\u001b[0m\u001b[48;2;240;255;240m──────────────────────────────────────────\u001b[0m Validated Output \u001b[48;2;240;255;240m───────────────────────────────────────────\u001b[0m\u001b[48;2;240;255;240m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m│\u001b[0m\u001b[48;2;240;255;240m \u001b[0m\u001b[48;2;240;255;240m''\u001b[0m\u001b[48;2;240;255;240m                                                                                                     \u001b[0m\u001b[48;2;240;255;240m \u001b[0m\u001b[48;2;240;255;240m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(guard.history.last.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the translation quality is really bad, and the `HighQualityTranslation` check failed as the translation quality was below the threshold. The validated response is an empty string.\n",
    "\n",
    "## In this way, you can use Guardrails to ensure that the output of your LLM is of high quality.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311lite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
